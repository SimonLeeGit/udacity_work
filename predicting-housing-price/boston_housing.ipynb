{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习工程师纳米学位\n",
    "## 模型评价与验证\n",
    "## 项目 1: 预测波士顿房价\n",
    "\n",
    "\n",
    "欢迎来到机器学习工程师纳米学位的第一个项目！在此文件中，有些示例代码已经提供给你，但你还需要实现更多的功能来让项目成功运行。除非有明确要求，你无须修改任何已给出的代码。代码栏有TODO的表示接下来的内容中有需要你必须实现的功能，请仔细阅读所有的提示！\n",
    "\n",
    "除了实现代码外，你还**必须**回答一些与项目和实现有关的问题，请仔细阅读每个问题，并且在问题后的**'回答'**文字框中写出完整的答案。审阅者将会根据你对问题的回答和撰写代码所实现的功能来对你的项目进行审阅。\n",
    "\n",
    ">**提示：**Code 和 Markdown 区域可通过 **Shift + Enter** 快捷键运行。此外，Markdown可以通过双击进入编辑模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第一步. 导入数据\n",
    "在这个项目中，你将利用爱荷华州埃姆斯的个人住宅物业销售情况所整理的波士顿房屋信息数据来训练和测试一个模型，并对模型的性能和预测能力进行测试。通过该数据训练好的模型可以被用来对房屋的价值做特定预测。对于房地产经纪人等类型的日常工作来说，这样的预测模型已经被证明非常有价值。\n",
    "\n",
    "此项目的数据集来自[kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)的原始数据，未经过任何处理。该数据集统计了2006年至2010年波士顿个人住宅销售情况，包含2900多个观测资料（其中一半是训练数据，即我们的`housedata.csv`文件）。更多文档信息可以参考作者的[document](http://jse.amstat.org/v19n3/decock.pdf)（可不看），以及项目附件`data_description.txt`文件（特征描述文件，要看）。\n",
    "\n",
    "运行下面区域的代码以载入波士顿房屋训练数据集，以及一些此项目所需的Python库。如果成功返回数据集的大小，表示数据集已载入成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入此项目需要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import visuals as vs # Supplementary code\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn') # use seaborn style\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题1：加载波士顿房屋训练数据`housedata.csv`**："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston housing dataset has 1460 data points with 81 variables each.\n"
     ]
    }
   ],
   "source": [
    "# 1 TODO：载入波士顿房屋的数据集：使用pandas载入csv，并赋值到data_df\n",
    "data_df = pd.read_csv('housedata.csv')\n",
    "\n",
    "# 成功载入的话输出训练数据行列数目\n",
    "print(\"Boston housing dataset has {} data points with {} variables each.\".format(*data_df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第二步. 观察数据\n",
    "这个部分，你会对波士顿房地产数据进行初步的观察并给出你的分析。通过对数据的探索来熟悉数据可以让你更好地理解数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题2.1：打印并观察前5条`data_df`数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
      "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
      "\n",
      "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0      2   2008        WD         Normal     208500  \n",
      "1      5   2007        WD         Normal     181500  \n",
      "2      9   2008        WD         Normal     223500  \n",
      "3      2   2006        WD        Abnorml     140000  \n",
      "4     12   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# 2.1 TODO: 打印出前5条data_df\n",
    "print(data_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题2.2：Id特征对我们训练数据没有任何用处，在`data_df`中删除`'Id'`列数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 TODO: 删除data_df中的Id特征（保持数据仍在data_df中，不更改变量名）\n",
    "data_df = data_df.drop('Id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题2.3：使用describe方法观察`data_df`各个特征的统计信息：**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>46.549315</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>161.319273</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1474.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  1460.000000  1201.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     56.897260    70.049958   10516.828082     6.099315     5.575342   \n",
       "std      42.300571    24.284752    9981.264932     1.382997     1.112799   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    59.000000    7553.500000     5.000000     5.000000   \n",
       "50%      50.000000    69.000000    9478.500000     6.000000     5.000000   \n",
       "75%      70.000000    80.000000   11601.500000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  \\\n",
       "count  1460.000000   1460.000000  1452.000000  1460.000000  1460.000000   \n",
       "mean   1971.267808   1984.865753   103.685262   443.639726    46.549315   \n",
       "std      30.202904     20.645407   181.066207   456.098091   161.319273   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000   \n",
       "25%    1954.000000   1967.000000     0.000000     0.000000     0.000000   \n",
       "50%    1973.000000   1994.000000     0.000000   383.500000     0.000000   \n",
       "75%    2000.000000   2004.000000   166.000000   712.250000     0.000000   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1474.000000   \n",
       "\n",
       "           ...         WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count      ...        1460.000000  1460.000000    1460.000000  1460.000000   \n",
       "mean       ...          94.244521    46.660274      21.954110     3.409589   \n",
       "std        ...         125.338794    66.256028      61.119149    29.317331   \n",
       "min        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "25%        ...           0.000000     0.000000       0.000000     0.000000   \n",
       "50%        ...           0.000000    25.000000       0.000000     0.000000   \n",
       "75%        ...         168.000000    68.000000       0.000000     0.000000   \n",
       "max        ...         857.000000   547.000000     552.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1460.000000  1460.000000   \n",
       "mean     15.060959     2.758904     43.489041     6.321918  2007.815753   \n",
       "std      55.757415    40.177307    496.123024     2.703626     1.328095   \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000   \n",
       "25%       0.000000     0.000000      0.000000     5.000000  2007.000000   \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000   \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000   \n",
       "max     480.000000   738.000000  15500.000000    12.000000  2010.000000   \n",
       "\n",
       "           SalePrice  \n",
       "count    1460.000000  \n",
       "mean   180921.195890  \n",
       "std     79442.502883  \n",
       "min     34900.000000  \n",
       "25%    129975.000000  \n",
       "50%    163000.000000  \n",
       "75%    214000.000000  \n",
       "max    755000.000000  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 TODO:\n",
    "data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于这个项目的最终目标是建立一个预测房屋价值的模型，我们需要将数据集分为**特征(features)**和**目标变量(target variable)**。\n",
    "- **目标变量**：` SalePrice`，是我们希望预测的变量。\n",
    "- **特征**：除` SalePrice`外的属性都是特征，给我们提供了每个数据点的数量相关的信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题2.4：通过观察数据，结合`data_description.txt`特征描述，整理出你认为跟目标变量最相关的5个特征，并进行部分解释**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题2.4：\n",
    " - LotArea: 根据数据LotArea越大，对应的SalePrice也会越大；\n",
    " - OverallCond: 根据数据OverallCond越好，对应的SalePrice也会越大；\n",
    " - YearBuilt: 根据数据YearBuilt越新，对应的SalePrice也会越大；\n",
    " - HouseStyle: 根据数据HouseStyle为2Story的，对应的SalePrice也会越大；\n",
    " - GrLivArea: 根据数据GrLivArea越大，对应的SalePrice也会越大；\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第三步. 数据预处理\n",
    "关于第三步，我们的数据不可能是百分百的干净数据（有用数据），总会在采集整理时有些”失误“，“冗余”，造成脏数据，所以我们要从数据的正确性，完整性来清理下数据。\n",
    "- **正确性**：一般是指有没有异常值，比如我们这个数据集中作者的[document](http://jse.amstat.org/v19n3/decock.pdf)所说：\n",
    "`I would recommend removing any houses with more than 4000 square feet from the data set (which eliminates these five unusual observations) before assigning it to students.`\n",
    "建议我们去掉数据中`'GrLivArea'`中超过4000平方英尺的房屋，当然本数据集还有其他的异常点，这里不再处理。\n",
    "- **完整性**：采集或者整理数据时所造成的空数据决定了数据的完整性，通常我们会有一定的方法处理这些数据，以下我们使用以下两种方法，一是[这个](https://discuss.analyticsvidhya.com/t/what-should-be-the-allowed-percentage-of-missing-values/2456),即选择丢弃过多空数据的特征（或者直接丢弃数据行，前提是NA数据占比不多），二是填补数据，填补的方法也很多，均值/中位数/众数填充等等都是好方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3.1：画出`'GrLivArea'`和`'SalePrice'`的关系图，x轴为`'GrLivArea'`，y轴为`'SalePrice'`，观察数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.1 TODO\n",
    "sns.jointplot(x=\"GrLivArea\", y=\"SalePrice\", data=data_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3.2：通过上图我们可以看到那几个异常值，即`'GrLivArea'`大于4000，但是`'SalePrice'`又极低的数据，从`data_df`删除这几个异常值，删除后重新绘制`'GrLivArea'`和`'SalePrice'`的关系图，确认异常值已删除。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[(60, 'RL', 130.0, 40094, 'Pave', nan, 'IR1', 'Bnk', 'AllPub', 'Inside', 'Gtl', 'Edwards', 'PosN', 'PosN', '1Fam', '2Story', 10, 5, 2007, 2008, 'Hip', 'CompShg', 'CemntBd', 'CmentBd', 'Stone', 762.0, 'Ex', 'TA', 'PConc', 'Ex', 'TA', 'Gd', 'GLQ', 2260, 'Unf', 0, 878, 3138, 'GasA', 'Ex', 'Y', 'SBrkr', 3138, 1538, 0, 4676, 1, 0, 3, 1, 3, 1, 'Ex', 11, 'Typ', 1, 'Gd', 'BuiltIn', 2007.0, 'Fin', 3, 884, 'TA', 'TA', 'Y', 208, 406, 0, 0, 0, 0, nan, nan, nan, 0, 10, 2007, 'New', 'Partial', 184750)\\n (60, 'RL', 313.0, 63887, 'Pave', nan, 'IR3', 'Bnk', 'AllPub', 'Corner', 'Gtl', 'Edwards', 'Feedr', 'Norm', '1Fam', '2Story', 10, 5, 2008, 2008, 'Hip', 'ClyTile', 'Stucco', 'Stucco', 'Stone', 796.0, 'Ex', 'TA', 'PConc', 'Ex', 'TA', 'Gd', 'GLQ', 5644, 'Unf', 0, 466, 6110, 'GasA', 'Ex', 'Y', 'SBrkr', 4692, 950, 0, 5642, 2, 0, 2, 1, 3, 1, 'Ex', 12, 'Typ', 3, 'Gd', 'Attchd', 2008.0, 'Fin', 2, 1418, 'TA', 'TA', 'Y', 214, 292, 0, 0, 0, 480, 'Gd', nan, nan, 0, 1, 2008, 'New', 'Partial', 160000)] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-2b8a9009a336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 3.2.1 TODO 从train_df删除GrLivArea大于4000且SalePrice低于300000的值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GrLivArea'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4000\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SalePrice'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3695\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3697\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3699\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3111\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3141\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3143\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3144\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4402\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4403\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4404\u001b[0;31m                     '{} not found in axis'.format(labels[mask]))\n\u001b[0m\u001b[1;32m   4405\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4406\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[(60, 'RL', 130.0, 40094, 'Pave', nan, 'IR1', 'Bnk', 'AllPub', 'Inside', 'Gtl', 'Edwards', 'PosN', 'PosN', '1Fam', '2Story', 10, 5, 2007, 2008, 'Hip', 'CompShg', 'CemntBd', 'CmentBd', 'Stone', 762.0, 'Ex', 'TA', 'PConc', 'Ex', 'TA', 'Gd', 'GLQ', 2260, 'Unf', 0, 878, 3138, 'GasA', 'Ex', 'Y', 'SBrkr', 3138, 1538, 0, 4676, 1, 0, 3, 1, 3, 1, 'Ex', 11, 'Typ', 1, 'Gd', 'BuiltIn', 2007.0, 'Fin', 3, 884, 'TA', 'TA', 'Y', 208, 406, 0, 0, 0, 0, nan, nan, nan, 0, 10, 2007, 'New', 'Partial', 184750)\\n (60, 'RL', 313.0, 63887, 'Pave', nan, 'IR3', 'Bnk', 'AllPub', 'Corner', 'Gtl', 'Edwards', 'Feedr', 'Norm', '1Fam', '2Story', 10, 5, 2008, 2008, 'Hip', 'ClyTile', 'Stucco', 'Stucco', 'Stone', 796.0, 'Ex', 'TA', 'PConc', 'Ex', 'TA', 'Gd', 'GLQ', 5644, 'Unf', 0, 466, 6110, 'GasA', 'Ex', 'Y', 'SBrkr', 4692, 950, 0, 5642, 2, 0, 2, 1, 3, 1, 'Ex', 12, 'Typ', 3, 'Gd', 'Attchd', 2008.0, 'Fin', 2, 1418, 'TA', 'TA', 'Y', 214, 292, 0, 0, 0, 480, 'Gd', nan, nan, 0, 1, 2008, 'New', 'Partial', 160000)] not found in axis\""
     ]
    }
   ],
   "source": [
    "# 3.2.1 TODO 从train_df删除GrLivArea大于4000且SalePrice低于300000的值\n",
    "rows=[x for i,x in data_df.iterrows() if x['GrLivArea'] > 4000 and x['SalePrice'] < 300000]\n",
    "data_df.drop(rows, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2.2 TODO 重新绘制GrLivArea和SalePrice的关系图，确认异常值已删除\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题3.3：筛选出过多空数据的特征，我们这个项目定为筛选出超过25%的空数据的特征**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_percent = 0.25\n",
    "limit_value = len(data_df) * limit_percent\n",
    "# 3.3.1 TODO 统计并打印出超过25%的空数据的特征\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**如果你整理出的特征是`'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature'`，那就说明你统计对了，接着我们查看`data_description.txt`文件，就会发现，这些并非一定是空缺数据，而没有游泳池，篱笆等也会用NA来表示，那么就不需要删除这些特征了，而是用`None`来填充`NA`数据。**\n",
    "\n",
    "**问题3.4：根据`data_description.txt`特征描述填充空数据，数据填充什么已经整理好了，请按提示要求来进行填充**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直接运行不用修改\n",
    "# 确定所有空特征\n",
    "missing_columns = list(data_df.columns[data_df.isnull().sum() != 0])\n",
    "# 确定哪些是类别特征，哪些是数值特征\n",
    "missing_numerical = list(data_df[missing_columns].dtypes[data_df[missing_columns].dtypes != 'object'].index)\n",
    "missing_category = [i for i in missing_columns if i not in missing_numerical]\n",
    "print(\"missing_numerical:\",missing_numerical)\n",
    "print(\"missing_category:\",missing_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要填充众数的特征\n",
    "fill_Mode = ['Electrical'] \n",
    "# 需要填充None的特征\n",
    "fill_None = ['Alley', 'MasVnrType', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "             'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \n",
    "             'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "# 需要填充0的特征\n",
    "fill_0 = ['GarageYrBlt']\n",
    "# 需要填充中位数的特征\n",
    "fill_median = ['LotFrontage', 'MasVnrArea']\n",
    "# 3.4.1 TODO：按需填补上面数据\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第四步. 探索性数据分析（EDA）\n",
    "在统计学中，探索性数据分析（EDA）是一种分析数据集以概括其主要特征的方法，通常使用可视化方法。虽然可以使用统计模型，但EDA主要是为了了解数据在形式化建模或假设测试任务之外能告诉我们什么。探索性数据分析是John Tukey提出的，鼓励业界利用统计学来研究数据，并尽可能提出假设，尽可能生成新的数据收集和实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、单变量分析（目标变量分析）\n",
    "既然要预测`'SalePrice'`，那么自然要先详细了解我们的目标变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题4.1：绘制`'SalePrice'`，并说明该直方图属于什么[分布](https://zh.wikipedia.org/wiki/%E5%81%8F%E5%BA%A6)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题4.1："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既然了解了目标变量，那么我们现在要从特征继续分析了，我们的`data_df`总共有81个特征，我们不可能用这么高维度的数据来进行预测，自然要剔除那些无关紧要的特征（噪声），使用真正关键的特征来进行模型训练，那么下面就让我们从主观与客观的两个方面来筛选特征。\n",
    "### 二、多变量主观分析（特征与目标变量的关系）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题4.2：问题2.4回答的5个你认为与`'SalePrice'`最相关特征，绘制他们分别与`'SalePrice'`的关系图，x轴为自选特征，y轴为`'SalePrice'`，根据关系图所示进行总结说明问题2.4的所猜测的关系是否正确**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三、多变量客观分析（特征与目标变量的关系）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主观分析方面是自己选出了几个认为和`'SalePrice'`强相关的特征，但是这种是没有客观依据的，而且如果特征极其多，很难清晰的看到特征与目标变量之间的关系，就需要利用统计知识来进行多变量分析了。我们常使用热图heatmap结合corr来进行客观分析，热图Heatmap可以用颜色变化来反映变量之间的相关性二维矩阵或说相关性表格中的数据信息，它可以直观地将数据值的大小以定义的颜色深浅表示出来。这个项目，为了简化训练，我们以相关性绝对值大于0.5为界来选取我们需要的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不用修改直接运行\n",
    "corrmat = data_df.corr().abs()\n",
    "top_corr = corrmat[corrmat[\"SalePrice\"]>0.5].sort_values(by = [\"SalePrice\"], ascending = False).index\n",
    "cm = abs(np.corrcoef(data_df[top_corr].values.T))\n",
    "f, ax = plt.subplots(figsize=(20, 9))\n",
    "sns.set(font_scale=1.3)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True,\n",
    "                 square=True, fmt='.2f', annot_kws={'size': 13}, \n",
    "                 yticklabels=top_corr.values, xticklabels=top_corr.values);\n",
    "data_df = data_df[top_corr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第五步.特征分析\n",
    "有这么一句话在业界广泛流传：数据特征决定了机器学习的上限，而模型和算法只是逼近这个上限而已。特征工程，是整个数据分析过程中不可缺少的一个环节，其结果质量直接关系到模型效果和最终结论。从上面两步中我们得到了“干净”的数据，从庞大的特征群中筛选出了最相关的特征，也了解了我们目标数据的分布，那么接下来，我们从创造性方面来对我们的特征进行“改造”。\n",
    "- **创造性**：创造性主要是说两种情况，一种是对现有数据的处理，比如类别的One-hotEncoder独热编码或者LabelEncoder标签编码，数值的区间缩放，归一化标准化等等，另一种就是创造根据一些一个新的特征，例如某特征groupby后，或者某些特征组合后来创造新特征等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为我们特别筛选出来的特征都为数值类型特征，所以我们只做标准化的操作：这个项目是一个回归的项目，而我们的回归算法对标准正态分布预测较为准确，从我们的目标数据可以看出数据是一个偏态分步，那么我们使用log将数据从偏态分步转换为标准正态分布，最后进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不要修改，直接运行\n",
    "from scipy.special import boxcox1p\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data_df['SalePrice'] = np.log1p(data_df['SalePrice'])\n",
    "numeric_features = list(data_df.columns)\n",
    "numeric_features.remove('SalePrice')\n",
    "for feature in numeric_features:\n",
    "    #all_data[feat] += 1\n",
    "    data_df[feature] = boxcox1p(data_df[feature], 0.15)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data_df[numeric_features])\n",
    "data_df[numeric_features] = scaler.transform(data_df[numeric_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第六步.模型实现\n",
    "\n",
    "### 数据分割\n",
    "这部分正式开始模型实现与调参，首先我们要把`data_df`按特征和目标变量分开。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题6.1：将`data_df`分割为特征和目标变量**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 \n",
    "features = #TODO：提取除了SalePrice以外的特征赋值为features\n",
    "labels = #TODO：提取SalePrice作为labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，你需要把波士顿房屋数据集分成训练和测试两个子集。通常在这个过程中，数据也会被重新排列，以消除数据集中由于顺序而产生的偏差。\n",
    "在下面的代码中，你需要使用 `sklearn.model_selection` 中的 `train_test_split`， 将`features`和`prices`的数据都分成用于训练的数据子集和用于测试的数据子集。\n",
    "\n",
    " \n",
    "**问题6.2：将`features`，`labels`分隔为`X_train, X_test, y_train, y_test`**\n",
    "  - 分割比例为：80%的数据用于训练，20%用于测试；\n",
    "  - 选定一个数值以设定 `train_test_split` 中的 `random_state` ，这会确保结果的一致性；\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO：导入train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = # 6.2 TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题6.3：为什么要将数据集分为训练数据与测试数据？**\n",
    "\n",
    "**提示：** 如果没有数据来对模型进行测试，会出现什么问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.3："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **定义衡量标准**\n",
    "\n",
    "如果不能对模型的训练和测试的表现进行量化地评估，我们就很难衡量模型的好坏。通常我们会定义一些衡量标准，这些标准可以通过对某些误差或者拟合程度的计算来得到。在这个项目中，你将通过运算[*决定系数*](http://stattrek.com/statistics/dictionary.aspx?definition=coefficient_of_determination) R<sup>2</sup> 来量化模型的表现。模型的决定系数是回归分析中十分常用的统计信息，经常被当作衡量模型预测能力好坏的标准。\n",
    "\n",
    "R<sup>2</sup>的数值范围从0至1，表示**目标变量**的预测值和实际值之间的相关程度平方的百分比。一个模型的R<sup>2</sup> 值为0还不如直接用**平均值**来预测效果好；而一个R<sup>2</sup> 值为1的模型则可以对目标变量进行完美的预测。从0至1之间的数值，则表示该模型中目标变量中有百分之多少能够用**特征**来解释。_模型也可能出现负值的R<sup>2</sup>，这种情况下模型所做预测有时会比直接计算目标变量的平均值差很多。_\n",
    "\n",
    "**问题6.4：在下方代码的 `performance_metric` 函数中，你要实现：**\n",
    "- 使用 `sklearn.metrics` 中的 [`r2_score`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html) 来计算 `y_true` 和 `y_predict`的R<sup>2</sup>值，作为对其表现的评判。\n",
    "- 将他们的表现评分储存到`score`变量中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO： 导入r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\"计算并返回预测值相比于预测值的分数\"\"\"\n",
    "    \n",
    "    score =  # TODO 6.4\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题6.4 - 拟合程度**\n",
    "\n",
    "假设一个数据集有五个数据且一个模型做出下列目标变量的预测：\n",
    "\n",
    "| 真实数值 | 预测数值 |\n",
    "| :-------------: | :--------: |\n",
    "| 3.0 | 2.5 |\n",
    "| -0.5 | 0.0 |\n",
    "| 2.0 | 2.1 |\n",
    "| 7.0 | 7.8 |\n",
    "| 4.2 | 5.3 |\n",
    "*你觉得这个模型已成功地描述了目标变量的变化吗？如果成功，请解释为什么，如果没有，也请给出原因。*  \n",
    "\n",
    "**提示**：使用`performance_metric`函数来计算模型的决定系数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算这个模型的预测结果的决定系数\n",
    "score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n",
    "print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.4："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **学习曲线**\n",
    "\n",
    "后面的课程中会对各个算法模型有详细的介绍，我们这里就先选用决策树算法来进行训练（算法本身不是本次重点）。\n",
    "\n",
    "现在我们的重点是来看一下不同参数下，模型在训练集和验证集上的表现。这里，我们专注于决策树和这个算法的一个参数 `'max_depth'`。用全部训练集训练，选择不同`'max_depth'` 参数，观察这一参数的变化如何影响模型的表现。画出模型的表现来对于分析过程十分有益，这可以让我们看到一些单看结果看不到的行为。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据不同的训练集大小，和最大深度，生成学习曲线\n",
    "vs.ModelLearning(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题 6.5：选择上述图像中的其中一个，并给出其最大深度。随着训练数据量的增加，训练集曲线（Training）的评分有怎样的变化？验证集曲线（validation）呢？如果有更多的训练数据，是否能有效提升模型的表现呢？**\n",
    "\n",
    "**提示：**学习曲线的评分是否最终会收敛到特定的值？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.5："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 复杂度曲线\n",
    "下列代码内的区域会输出一幅图像，它展示了一个已经经过训练和验证的决策树模型在不同最大深度条件下的表现。这个图形将包含两条曲线，一个是训练集的变化，一个是验证集的变化。跟**学习曲线**相似，阴影区域代表该曲线的不确定性，模型训练和测试部分的评分都用的 `performance_metric` 函数。\n",
    "\n",
    "运行下方区域中的代码，并利用输出的图形并回答下面的两个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据不同的最大深度参数，生成复杂度曲线\n",
    "vs.ModelComplexity(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题6.6：当模型以最大深度 1训练时，模型的预测是出现很大的偏差还是出现了很大的方差？当模型以最大深度10训练时，情形又如何呢？图形中的哪些特征能够支持你的结论？你认为最大深度是多少的模型能够最好地对未见过的数据进行预测？**\n",
    "  \n",
    "**提示：** 你如何得知模型是否出现了偏差很大或者方差很大的问题？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.6："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题 6.7：什么是网格搜索法？如何用它来优化模型？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.7："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 交叉验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题 6.8:**\n",
    "- 什么是K折交叉验证法（k-fold cross-validation）？\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)是如何结合交叉验证来完成对最佳参数组合的选择的？\n",
    "- [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)中的`'cv_results_'`属性能告诉我们什么？\n",
    "- 网格搜索时如果不使用交叉验证会有什么问题？交叉验证又是如何解决这个问题的？\n",
    "\n",
    "**提示：** 在下面 fit_model函数最后加入 `print(pd.DataFrame(grid.cv_results_))` 可以帮你查看更多信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题6.8："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练最优模型\n",
    "在这个练习中，你需要将所学到的内容整合，使用**决策树算法**训练一个模型。为了得到的模型是一个最优模型，你需要使用网格搜索法训练模型，以找到最佳的 `max_depth` 参数。你可以把`max_depth` 参数理解为决策树算法在做出预测前，允许其对数据提出问题的数量。决策树是**监督学习算法**中的一种。\n",
    "\n",
    "**问题6.9:**\n",
    "\n",
    "在下方 `fit_model` 函数中，你需要做的是：\n",
    "1. **定义 `cross_validator` 变量**: 使用 `sklearn.model_selection` 中的 [`KFold`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) 创建一个交叉验证生成器对象;\n",
    "2. **定义 `regressor` 变量**: 使用  `sklearn.tree` 中的 [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) 创建一个决策树的回归函数;\n",
    "3. **定义 `params` 变量**: 为 `max_depth` 参数创造一个字典，它的值是从1至10的数组;\n",
    "4. **定义 `scoring_fnc` 变量**: 使用 `sklearn.metrics` 中的 [`make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html)  创建一个评分函数；\n",
    " 将 `performance_metric` 作为参数传至这个函数中；\n",
    "5. **定义 `grid` 变量**: 使用 `sklearn.model_selection` 中的 [`GridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) 创建一个网格搜索对象；将变量`regressor`, `params`, `scoring_fnc`和 `cross_validator` 作为参数传至这个对象构造函数中；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.9 TODO 导入 'KFold' 'DecisionTreeRegressor' 'make_scorer' 'GridSearchCV' \n",
    "\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" 基于输入数据 [X,y]，利于网格搜索找到最优的决策树模型\"\"\"\n",
    "    cross_validator = #TODO kfold\n",
    "    regressor = # TODO DecisionTreeRegressor\n",
    "    params = # TODO 创建字典\n",
    "    scoring_fnc = # TODO make scorer\n",
    "    grid = # TODO GridSearchCV\n",
    "    # 基于输入数据 [X,y]，进行网格搜索\n",
    "    grid = grid.fit(X, y)\n",
    "    # 返回网格搜索后的最优模型\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行下方区域内的代码，将决策树回归函数代入训练数据的集合，以得到最优化的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于训练数据，获得最优模型\n",
    "optimal_reg = fit_model(X_train, y_train)\n",
    "\n",
    "# 输出最优模型的 'max_depth' 参数\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(optimal_reg.get_params()['max_depth']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 第七步.做出预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终，使用我们确认好的参数来对测试数据进行预测，完成下面的问题，来看看我们的训练结果如何吧\n",
    "\n",
    "**问题7.1：填入上题所确认的最优参数，查看测试结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = \n",
    "regressor = DecisionTreeRegressor(max_depth = depth)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "score = performance_metric(y_test, y_pred)\n",
    "print(\"The R2 score is \",score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**问题7.2：你刚刚计算了最优模型在测试集上的决定系数，你会如何评价这个结果？**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回答问题7.2："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 选做"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "至此，我们的整个训练流程基本结束，当然我们只调试了`max_depth`参数，让我们达到了上面的那个最优结果，尝试修改问题6.9中的代码，修改[更多决策树的参数](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html)，来提高分数，期待你得到更好的成绩。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
